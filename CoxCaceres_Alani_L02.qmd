---
title: "Executive Summary: L02 More Models"
subtitle: "Data Science 3 with R (STAT 301-3)"
author: "Alani Cox-Caceres"

format:
  html:
    toc: true
    embed-resources: true
    code-fold: show
    link-external-newwindow: true
    
execute:
  warning: false
  echo: false

from: markdown+emoji  
---

## Github Repo Link

[https://github.com/STAT301-3-2023SP/L02-more-models-alanicc](https://github.com/STAT301-3-2023SP/L02-more-models-alanicc)


## Goal

The goal of this lab is to predict whether or not a wildfire will reach the wildlife protection zone of a national park. 

## Dataset

This summary utilizes the `wildfires.csv` dataset contained in the **data** subdirectory. this data comes from a population of 500 wildfires within that park. The dataset has 16 variables in total, but I only observed 14 with the target variable being wlf (variable determining whether or not the fire reached the protection zone). 

## Models

To analyze this data, I used 8 different models: k-nearest, random forest, boosted tree, elastic net with two-way interactions, radial support vector machine, polynomial support vector machine, single layer neural network, and a multivariate adaptive regression spline model. 

I split the data into a 20/80 split with the training data being the majority, and stratified the `wlf` variable to maintain balance. I used a v-fold cross-validation with 5 folds and repeated them 3 times. In this v-fold cross-validation, the data was split into 5 folds and the procedure was repeated 3 times. Ultimately, this model evaluation method reports the mean result across all folds from all runs. The metric I used to test accuracy was roc_auc, and I performed a confusion matrix on the best final model. A roc_auc score determines how efficient the model is, and a confusion matrix is a table that displays the numerous outcomes of the predictions and results from the dataset. 

## Model Performance

The best performance metric and runtimes for each model are shown below:

```{r}
# packages
library(kableExtra)

#table/graph here
load("results/result_table.rda")
kableExtra::kable(result_table) %>% 
  kableExtra::kable_minimal()

```

Here are the same results displayed as a graph:

```{r}
# packages
library(tidyverse)
library(tidymodels)
library(knitr)

#table/graph here
knitr::include_graphics("data/model_set_plot.png")

```

These results reveal that the multivariate adaptive regression spline model (mars) performed the best in its predictions. The roc_auc score for this model was 0.89, and the runtime was 16.371, which makes it the most accurate and second-fastest model I ran. 

```{r}
#table/graph here
load("results/mars_metric.rda")
kableExtra::kable(mars_metric) %>% 
  kableExtra::kable_minimal()
```

This table displays the best metrics that were found for the mars model. 

```{r}
#table/graph here
knitr::include_graphics("data/mars_roc_auc.png")
```

This graph visualizes the roc_auc curve for the mars model. Overall, it seems the model performed relatively well. 


Finally, I used this model to create a confusion matrix of the resulting predictions:

```{r}
#table/graph here
knitr::include_graphics("data/conf_mat.png")
```

Although these are not the best results, I am still happy with how the model performed and it was able to create relatively accurate predictions within a short period of time. In the future, I'd like to spend more time testing different metrics to determine ways to improve the final predictions. Overall, I found that the mars model was effective in predicting the effects of wildfires in national parks, and I am content with my data exploration.

## Github Repo Link

[https://github.com/STAT301-3-2023SP/L02-more-models-alanicc](https://github.com/STAT301-3-2023SP/L02-more-models-alanicc)
